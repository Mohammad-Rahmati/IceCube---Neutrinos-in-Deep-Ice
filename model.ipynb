{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('clear')\n",
    "import pandas as pd\n",
    "from typing import Any, Dict, List\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.optim.adam import Adam\n",
    "from graphnet.data.constants import FEATURES, TRUTH\n",
    "from graphnet.models import StandardModel\n",
    "from graphnet.models.detector.icecube import IceCubeKaggle\n",
    "from graphnet.models.gnn import DynEdge\n",
    "from graphnet.models.graph_builders import KNNGraphBuilder\n",
    "from graphnet.models.task.reconstruction import DirectionReconstructionWithKappa\n",
    "from graphnet.training.callbacks import PiecewiseLinearLR\n",
    "from graphnet.training.loss_functions import VonMisesFisher3DLoss\n",
    "from graphnet.training.labels import Direction\n",
    "from graphnet.training.utils import make_dataloader\n",
    "import torch\n",
    "import time\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(config: Dict[str,Any], train_dataloader: Any) -> StandardModel:\n",
    "    \n",
    "    detector = IceCubeKaggle(\n",
    "        graph_builder=KNNGraphBuilder(nb_nearest_neighbours=8),\n",
    "    )\n",
    "    gnn = DynEdge(\n",
    "        nb_inputs=detector.nb_outputs,\n",
    "        global_pooling_schemes=[\"min\", \"max\", \"mean\", \"sum\"]\n",
    "    )\n",
    "    \n",
    "    task = DirectionReconstructionWithKappa(\n",
    "        hidden_size=gnn.nb_outputs,\n",
    "        target_labels=config[\"target\"],\n",
    "        loss_function=VonMisesFisher3DLoss(),\n",
    "    )\n",
    "    prediction_columns = [config[\"target\"] + \"_x\", \n",
    "                            config[\"target\"] + \"_y\", \n",
    "                            config[\"target\"] + \"_z\", \n",
    "                            config[\"target\"] + \"_kappa\" ]\n",
    "                            \n",
    "    additional_attributes = ['zenith', 'azimuth', 'event_id']\n",
    "\n",
    "    model = StandardModel(\n",
    "        detector=detector,\n",
    "        gnn=gnn,\n",
    "        tasks=[task],\n",
    "        optimizer_class=Adam,\n",
    "        optimizer_kwargs={\"lr\": 1e-03, \"eps\": 1e-03},\n",
    "        scheduler_class=PiecewiseLinearLR,\n",
    "        scheduler_kwargs={\n",
    "            \"milestones\": [\n",
    "                0,\n",
    "                len(train_dataloader) / 2,\n",
    "                len(train_dataloader) * config[\"fit\"][\"max_epochs\"],\n",
    "            ],\n",
    "            \"factors\": [1e-02, 1, 1e-02],\n",
    "        },\n",
    "        scheduler_config={\n",
    "            \"interval\": \"step\",\n",
    "        },\n",
    "    )\n",
    "    model.prediction_columns = prediction_columns\n",
    "    model.additional_attributes = additional_attributes\n",
    "    \n",
    "    return model\n",
    "\n",
    "def make_dataloaders(config: Dict[str, Any]) -> List[Any]:\n",
    "    \n",
    "    train_dataloader = make_dataloader(db = config['path'],\n",
    "                                            selection = pd.read_pickle(config['train_selection'])[config['index_column']].ravel().tolist(),\n",
    "                                            pulsemaps = config['pulsemap'],\n",
    "                                            features = features,\n",
    "                                            truth = truth,\n",
    "                                            batch_size = config['batch_size'],\n",
    "                                            num_workers = config['num_workers'],\n",
    "                                            shuffle = True,\n",
    "                                            labels = {'direction': Direction()},\n",
    "                                            index_column = config['index_column'],\n",
    "                                            truth_table = config['truth_table'],\n",
    "                                            )\n",
    "    \n",
    "    validate_dataloader = make_dataloader(db = config['path'],\n",
    "                                            selection = pd.read_pickle(config['validate_selection'])[config['index_column']].ravel().tolist(),\n",
    "                                            pulsemaps = config['pulsemap'],\n",
    "                                            features = features,\n",
    "                                            truth = truth,\n",
    "                                            batch_size = config['batch_size'],\n",
    "                                            num_workers = config['num_workers'],\n",
    "                                            shuffle = False,\n",
    "                                            labels = {'direction': Direction()},\n",
    "                                            index_column = config['index_column'],\n",
    "                                            truth_table = config['truth_table'],\n",
    "                                            )\n",
    "                                            \n",
    "    return train_dataloader, validate_dataloader\n",
    "\n",
    "def train_dynedge_from_scratch(config: Dict[str, Any]) -> StandardModel:\n",
    "\n",
    "    train_dataloader, validate_dataloader = make_dataloaders(config = config)\n",
    "\n",
    "    model = build_model(config, train_dataloader)\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=config[\"early_stopping_patience\"],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_dataloader,\n",
    "        validate_dataloader,\n",
    "        callbacks=callbacks,\n",
    "        **config[\"fit\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Constants\n",
    "features = FEATURES.KAGGLE\n",
    "truth = TRUTH.KAGGLE\n",
    "\n",
    "# Configuration\n",
    "idx = 0\n",
    "config = {\n",
    "        \"path\": f'data/extra_big_batch_{idx}.db',\n",
    "        \"inference_database_path\": '',\n",
    "        \"pulsemap\": 'pulse_table',\n",
    "        \"truth_table\": 'meta_table',\n",
    "        \"features\": features,\n",
    "        \"truth\": truth,\n",
    "        \"index_column\": 'event_id',\n",
    "        \"run_name_tag\": 'my_example',\n",
    "        \"batch_size\": 512,\n",
    "        \"num_workers\": 32,\n",
    "        \"target\": 'direction',\n",
    "        \"early_stopping_patience\": 5,\n",
    "        \"fit\": {\n",
    "                \"max_epochs\": 200,\n",
    "                \"gpus\": [0],\n",
    "                \"distribution_strategy\": None,\n",
    "                \"ckpt_path\": None\n",
    "                },\n",
    "        'train_selection': f'./data/validate_selection_max_200_pulses_{idx}.pkl',\n",
    "        'validate_selection': f'./data/validate_selection_max_200_pulses_{idx}.pkl',\n",
    "        \n",
    "        'test_selection': None,\n",
    "        'base_dir': 'training'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_dataloader = make_dataloader(db = config['path'],\n",
    "                                            selection = pd.read_pickle(config['validate_selection'])[config['index_column']].ravel().tolist(),\n",
    "                                            pulsemaps = config['pulsemap'],\n",
    "                                            features = features,\n",
    "                                            truth = truth,\n",
    "                                            batch_size = config['batch_size'],\n",
    "                                            num_workers = config['num_workers'],\n",
    "                                            shuffle = False,\n",
    "                                            labels = {'direction': Direction()},\n",
    "                                            index_column = config['index_column'],\n",
    "                                            truth_table = config['truth_table'],\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validate_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_dynedge_from_scratch(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
