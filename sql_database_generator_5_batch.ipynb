{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[32mINFO    \u001b[0m 2023-02-25 06:59:22 - get_logger - Writing log to \u001b[1mlogs/graphnet_20230225-065922.log\u001b[0m\n",
      "\u001b[1;34mgraphnet\u001b[0m: \u001b[33mWARNING \u001b[0m 2023-02-25 06:59:23 - warn_once - `icecube` not available. Some functionality may be missing.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from graphnet.data.sqlite.sqlite_utilities import create_table\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pyarrow.parquet as pq\n",
    "import sqlalchemy\n",
    "from tqdm import tqdm\n",
    "from typing import Any, Dict, List, Optional\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_folder = './data/train'\n",
    "meta_data_path = './data/train_meta.parquet'\n",
    "geometry_table = pd.read_csv('./data/sensor_geometry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input(meta_batch: pd.DataFrame, input_data_folder: str) -> pd.DataFrame:\n",
    "        batch_id = meta_batch['batch_id'].unique()\n",
    "        assert len(batch_id) == 1, \"contains multiple batch_ids. Did you set the batch_size correctly?\"\n",
    "        \n",
    "        detector_readings = pd.read_parquet(path = f'{input_data_folder}/batch_{batch_id[0]}.parquet')\n",
    "        sensor_positions = geometry_table.loc[detector_readings['sensor_id'], ['x', 'y', 'z']]\n",
    "        sensor_positions.index = detector_readings.index\n",
    "\n",
    "        for column in sensor_positions.columns:\n",
    "            if column not in detector_readings.columns:\n",
    "                detector_readings[column] = sensor_positions[column]\n",
    "\n",
    "        detector_readings['auxiliary'] = detector_readings['auxiliary'].replace({True: 1, False: 0})\n",
    "        return detector_readings.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_table(database_path: str,\n",
    "                      df: pd.DataFrame,\n",
    "                      table_name:  str,\n",
    "                      is_primary_key: bool,\n",
    "                      engine: sqlalchemy.engine.base.Engine) -> None:\n",
    "                      \n",
    "    try:\n",
    "        create_table(   columns=  df.columns,\n",
    "                        database_path = database_path, \n",
    "                        table_name = table_name,\n",
    "                        integer_primary_key= is_primary_key,\n",
    "                        index_column = 'event_id')\n",
    "    except sqlite3.OperationalError as e:\n",
    "        if 'already exists' in str(e):\n",
    "            pass\n",
    "        else:\n",
    "            raise e\n",
    "   \n",
    "    df.to_sql(table_name, con=engine, index=False, if_exists=\"append\", chunksize = 200000)\n",
    "    engine.dispose()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sqlite(meta_data_path: str,\n",
    "                      database_path: str,\n",
    "                      input_data_folder: str,\n",
    "                      batch_size: int = 200000,\n",
    "                      batch_ids: list = [],\n",
    "                      engine: sqlalchemy.engine.base.Engine = None\n",
    "                      ) -> None:\n",
    "    \n",
    "    meta_data_iter = pq.ParquetFile(meta_data_path).iter_batches(batch_size = batch_size)\n",
    "    batch_id = 1\n",
    "    converted_batches = []\n",
    "    for meta_data_batch in meta_data_iter:\n",
    "        if batch_id in batch_ids:\n",
    "            meta_data_batch  = meta_data_batch.to_pandas()\n",
    "            add_to_table(database_path = database_path,\n",
    "                        df = meta_data_batch,\n",
    "                        table_name='meta_table',\n",
    "                        is_primary_key= True,\n",
    "                        engine = engine)\n",
    "            pulses = load_input(meta_batch=meta_data_batch, input_data_folder= input_data_folder)\n",
    "            del meta_data_batch \n",
    "            add_to_table(database_path = database_path,\n",
    "                        df = pulses,\n",
    "                        table_name='pulse_table',\n",
    "                        is_primary_key= False,\n",
    "                        engine = engine)\n",
    "            del pulses \n",
    "            converted_batches.append(batch_id)\n",
    "        batch_id +=1\n",
    "        if len(batch_ids) == len(converted_batches):\n",
    "            break\n",
    "        gc.collect()\n",
    "    del meta_data_iter \n",
    "    print(f'Conversion Complete! Database available at\\n {database_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_dict = {}\n",
    "# list_train_ids = range(1,661)\n",
    "# for batch_number in range(0,10):\n",
    "#     list_dict[batch_number] = np.random.choice(list_train_ids, 66, replace=False)\n",
    "#     list_train_ids = [x for x in list_train_ids if x not in list_dict[batch_number]]\n",
    "#     print(f'Batch {batch_number} contains {len(list_dict[batch_number])} events')\n",
    "\n",
    "\n",
    "# with open('big_batch_indx.pkl', 'wb') as f:\n",
    "#     pickle.dump(list_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict = pd.read_pickle('big_batch_indx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([496, 303, 133,  61,   6, 547,  47,  20, 245, 464,  15, 148, 414,\n",
       "        230, 648,  84, 313, 258,  45, 165, 598, 277, 359,  33, 294,  60,\n",
       "        579,  72, 495, 617,  76, 139, 224, 343, 432, 349, 296, 244, 621,\n",
       "        260, 606,  74, 613, 342, 442, 158, 363, 307, 611, 480, 169, 346,\n",
       "         58, 115, 316,  73, 512, 118, 459, 433,  68, 630, 529, 614, 178,\n",
       "        491]),\n",
       " 1: array([ 83, 634, 341, 107, 543, 386, 513, 304, 179, 559, 589, 632, 636,\n",
       "        257, 151, 518,  90, 526, 227, 544, 379, 527, 242, 620,  17, 655,\n",
       "          2, 571, 328, 300, 546, 114, 237, 213, 440, 149, 403, 504, 436,\n",
       "        602,  77, 633, 574, 508,  29, 472, 154,  57, 159, 448, 385, 184,\n",
       "        171,  54, 401, 576, 295, 475, 657, 649,  75,  70, 145, 284, 365,\n",
       "        625]),\n",
       " 2: array([ 59, 506, 201, 212, 319, 132, 484, 357, 468, 534, 573, 441, 569,\n",
       "        396,  82, 545, 536, 537,  69, 298, 280, 530, 194, 120, 437, 270,\n",
       "          3, 420, 350, 137,  53, 498, 105,  78, 645, 155, 556, 608, 364,\n",
       "        218, 532, 279, 510, 641, 389, 434, 660, 658, 549,  97, 393, 500,\n",
       "        629, 190, 338, 240, 112, 380, 626, 642, 187,  13, 369, 347, 354,\n",
       "         86]),\n",
       " 3: array([ 18, 207, 619, 235, 302, 269, 551, 356,  80, 408, 603, 417, 121,\n",
       "        239, 320,  30, 497, 609, 103,  25, 292, 373, 402, 531, 301,  34,\n",
       "        117, 180, 125, 465,  26, 428, 493, 138, 276, 381,  44, 413, 228,\n",
       "        153, 358,  36, 644, 476, 406, 455, 548, 656, 473,  39, 221, 306,\n",
       "        168, 659, 134, 564, 470, 552, 214, 558, 591, 256, 136, 203, 339,\n",
       "        541]),\n",
       " 4: array([572, 226, 367, 281, 647, 466, 215, 208, 553, 588, 524, 287, 616,\n",
       "        106, 457, 595, 192,   9, 624, 652, 430, 289, 293,  43, 590, 384,\n",
       "        485, 522,  10, 189, 404, 317, 444, 334,  11, 323, 435, 370, 533,\n",
       "        129, 374, 566, 587, 421, 204, 605, 446,  23, 196, 310, 618, 345,\n",
       "        315, 561,  89, 122, 234, 160, 584, 344, 142, 265, 225, 361, 388,\n",
       "        200]),\n",
       " 5: array([286, 175, 324, 604, 219, 599, 156, 127, 489, 170, 627, 264, 130,\n",
       "        250, 288,  48, 282, 163, 220, 336, 469, 520, 412, 271, 144, 565,\n",
       "        426, 340, 400, 273, 327, 353,  67,  92, 488, 124, 261, 525, 405,\n",
       "        246, 188, 391, 333,  55, 157, 451, 259, 210, 416, 232, 199, 101,\n",
       "        211, 167,  32, 462, 567,  94, 335, 481, 431, 593,  99, 411, 161,\n",
       "        128]),\n",
       " 6: array([586, 581, 563,  85, 376, 297, 568, 217, 600, 575,  63, 309, 321,\n",
       "        528, 471, 387, 511, 162, 205, 577,  95, 263, 360, 375, 501, 427,\n",
       "        477, 314, 554, 461, 152, 494, 399, 449, 550, 460,   1,  24, 503,\n",
       "        312,  62,   4,  16, 423, 172, 141, 490, 299, 275, 424, 119, 487,\n",
       "        329, 366, 254, 492,   7, 623, 486, 478, 176, 285, 251, 185, 610,\n",
       "        202]),\n",
       " 7: array([ 52, 521, 538,  93, 111, 183, 348, 425,  28,  46, 479, 452, 173,\n",
       "        415, 519, 562, 331, 535,  91, 126, 177, 229, 191, 377, 643, 182,\n",
       "        483,  87, 352, 516, 422, 104,  35, 150, 249, 570, 238, 515, 557,\n",
       "        628, 325, 454,  66, 267, 555,  79, 390, 646, 517, 102, 318, 166,\n",
       "         56, 578, 582, 539, 110, 146, 197, 438, 407, 514, 262, 523, 272,\n",
       "        193]),\n",
       " 8: array([615, 231, 174, 247, 445, 638, 392,  42, 453, 382, 206, 311, 362,\n",
       "        274, 447, 253, 222, 502, 266, 355, 371, 198, 439,   8, 332, 131,\n",
       "        291,  22, 585,  96, 542, 596, 243, 135, 241, 580, 505,  31, 268,\n",
       "        100, 456,  64, 326, 592,  65, 651, 467, 597, 394,  49,  21, 650,\n",
       "        283, 509, 622, 463,  14, 429, 637,  98,  81, 278, 290, 308, 560,\n",
       "        653]),\n",
       " 9: array([ 50, 322, 209,  37,  38, 186, 123, 368, 635, 330, 236, 255, 147,\n",
       "        601, 143, 482, 216, 607, 248, 409, 372, 108,  40, 164, 507, 410,\n",
       "        612, 305, 195, 223,  41, 233,  88, 109, 398, 378, 252, 631, 113,\n",
       "        654,  19, 395,  27, 383, 450,  71, 639, 419, 397, 116,   5, 499,\n",
       "         12,  51, 443, 594, 418, 458, 351, 337, 181, 540, 640, 140, 583,\n",
       "        474])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [2:14:32<00:00, 8072.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion Complete! Database available at\n",
      " ./data/big_batch_5.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for batch_number in tqdm([5]):\n",
    "    database_path = f'./data/big_batch_{batch_number}.db'\n",
    "    engine = sqlalchemy.create_engine(\"sqlite:///\" + database_path)\n",
    "    convert_to_sqlite(meta_data_path,\n",
    "                    database_path=database_path,\n",
    "                    input_data_folder=input_data_folder,\n",
    "                    batch_size=200000,\n",
    "                    batch_ids=list_dict[batch_number],\n",
    "                    engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f831811ab5408f3cdb83b41500deeb387c9454d72d6267bf8a6ce625eb23eac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
